{'model': {'architecture': {'layers': 1, 'activation_function': 'ReLU', 'dropout': False, 'batchnorm': False, 'input_size': 3906}, 'hparams': {'latent_dims': 16, 'hidden_size_1': 64, 'hidden_size_2': 32, 'hidden_size_3': 32}}, 'optimiser': {'optimiser': {'optim': 'Adam', 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 40}, 'loss_func': {'cutoff_epoch': 0, 'error_relation': 0.01}}}